\documentstyle[12pt,fullpage,psfig]{article}

\title{rCBF Analysis Using MATLAB}
\author{Mark Wolforth \and Greg Ward}
\psdraft
\def\code#1{{\tt #1}}

\begin{document}

\maketitle
%\newpage

\tableofcontents

%--------------------------------------------------------------
\newpage
\section{Introduction}

This document is the user manual for the rCBF (regional Cerebral
Blood Flow) package developed at the Montreal Neurological Institute
McConnell Brain Imaging Centre during the summer of 1993.  This
kinetic analysis package runs under MATLAB, in conjunction with EMMA
(Extensible Matlab Medical Analysis), a package developed at the same
time.

The rCBF package described in this document performs a full
two-compartment analysis of cerebral blood flow, including performing
blood delay and dispersion correction.  It is intended as a working
example for future developers of MATLAB analysis packages, in
addition to being a useful analysis tool.  Therefore, this document
places more emphasis on the structure and organization of the
software than on the actual use of the software.

The authors would like to thank Sean Marrett for being the driving
force behind this project.  He provided invaluable guidance when all
seemed lost.

%--------------------------------------------------------------
\newpage
\section{Mathematical Analysis}

\subsection{Introduction}

The two-compartment cerebral blood flow model can be characterized by
the following three equations:

\begin{equation}
\frac{dM}{dt} = K_{1}C_{a}(t) - k_{2}M(t)      \label{eq:2comp1}
\end{equation}
\begin{equation}
M(t) = K_{1}C_{a}(t) \otimes e^{-k_{2}t}       \label{eq:2comp2}
\end{equation}
\begin{equation}
A(t) = M(t) + C_{a}(t)V_{0}                    \label{eq:2comp3}
\end{equation}

In these equations, $A(t)$ is the PET data collected over a set of
frames, $C_{a}(t)$ is the delay and dispersion corrected arterial
blood sample data, and $M(t)$ is the radioactive tracer activity
present in cerebral tissue.  We know both $A(t)$ and $C_{a}(t)$, but
cannot know $M(t)$ without knowing $V_{0}$.

One additional point to consider is that these equations are written
for continuous functions.  However, the PET data that is actually
available is average activity across each frame.  Therefore, in
order to solve the equations, we must average the non PET data
across frames.  By combining equations (\ref{eq:2comp2}) and
(\ref{eq:2comp3}), and averaging the non PET data over frames, we
get:

\begin{equation}
A^{*}(t) = \frac{\int_{T_1}^{T_2} K_{1} \left[ C_{a}(t) \otimes
e^{-k_{2}t} \right] + C_{a}(t)V_{0} dt}{T_{2} - T_{1}}
\label{eq:2comp4}
\end{equation}

where $A^{*}(t)$ is the PET data that is actually collected (by
definition, averaged over frames), and ${\int_{T_1}^{T_2}dt} / {(T_2 -
T_1)}$ performs an averaging over frames ($T_1$ is the frame start
time, $T_2$ is the frame stop time, and the integral is evaluated for
each frame).

We wish to solve equation (\ref{eq:2comp4}) for $K_{1}$, $k_{2}$, and
$V_{0}$.  Of course, one approach would be to try to perform an
explicit least squares curve fitting.  However, this approach would be
quite computationally intensive since the fitting would need to be
performed for every pixel of a $128 \times 128$ pixel image.  Fortunately,
there is a method of solution that gives good results with reduced
computational difficulty.

\subsection{Double-Weighted Integration Method}

\label{sec:double_weight}

Since the time required to perform a least squares curve fitting would
be prohibitive, a simpler approach to solving the problem is required.
One technique is to use a weighted integration method.  We initially
approached the problem by assuming that $V_{0}$ was negligibly small,
in which case the $C_{a}V_{0}$ term is eliminated from equation
(\ref{eq:2comp4}).  Taking equation (\ref{eq:2comp4}) with $C_{a}V_0$
eliminated, and integrating both sides from time 0 to the end of the
last frame, we get:

\begin{equation}
\int_{0}^{T} A^{*}(t) dt = K_{1} \int_{0}^{T} \frac{\int_{T_1}^{T_2}
\left[ C_{a}(u) \otimes e^{-k_{2}u} \right] du}{T_2 - T_1} dt
\end{equation}

We can then take this equation, and divide it by a weighted version
of itself:

\begin{equation}
\frac{\int_{0}^{T} A^{*}(t) dt}{\int_{0}^{T} A^{*}(t) t dt} =
\frac{K_{1} \int_{0}^{T} \frac{\int_{T_1}^{T_2} \left[ C_{a}(u)
\otimes e^{-k_{2}u} \right] du}{T_2 - T_1} dt}{K_{1} \int_{0}^{T}
\frac{\int_{T_1}^{T_2} \left[ C_{a}(u) \otimes e^{-k_{2}u} \right]
du}{T_2 - T_1} t dt}
\label{eq:1comp}
\end{equation}

$K_{1}$ cancels out of this equation, leaving us with an equation
that only involves $k_{2}$.  The left side of equation
(\ref{eq:1comp}) is easily evaluated by integrating the PET data.
The right side of equation (\ref{eq:1comp}) is not easily solved for
$k_{2}$, so a different approach was taken.  A look-up table was
generated relating values of $k_{2}$ to resulting values of the
right hand side of equation (\ref{eq:1comp}).  A linear
interpolation was then performed to choose values of $k_{2}$ from
this look-up table for each point in the left hand side of equation
(\ref{eq:1comp}).


\subsection{Triple-Weighted Integration Method}

In order to model the complete two-compartment system, we must be able
to solve equation (\ref{eq:2comp4}).  In section
\ref{sec:double_weight},
we solved the equation by multiplying by two different weights and
then dividing, and we can take a similar approach with the full
two-compartment equation.  We can weight equation (\ref{eq:2comp4})
with {\em three} different weights and then integrate:

\begin{equation}
\int_{0}^{T} w_{1}A^{*}(t)dt = K_{1} \int_{0}^{T} w_{1}
\frac{\int_{T_1}^{T_2} \left[ C_{a}(u) \otimes e^{-k_{2}u} \right]
du}{T_2 - T_1} dt + V_{0} \int_{0}^{T}w_{1} \frac{\int_{T_1}^{T_2}
C_{a}(u) du}{T_2 - T_1} dt \label{eq:fullweight1}
\end{equation}

\begin{equation}
\int_{0}^{T} w_{2}A^{*}(t)dt = K_{1} \int_{0}^{T} w_{2}
\frac{\int_{T_1}^{T_2} \left[ C_{a}(u) \otimes e^{-k_{2}u} \right]
du}{T_2 - T_1} dt + V_{0} \int_{0}^{T}w_{2} \frac{\int_{T_1}^{T_2}
C_{a}(u) du}{T_2 - T_1} dt \label{eq:fullweight2}
\end{equation}

\begin{equation}
\int_{0}^{T} w_{3}A^{*}(t)dt = K_{1} \int_{0}^{T} w_{3}
\frac{\int_{T_1}^{T_2} \left[ C_{a}(u) \otimes e^{-k_{2}u} \right]
du}{T_2 - T_1} dt + V_{0} \int_{0}^{T}w_{3} \frac{\int_{T_1}^{T_2}
C_{a}(u) du}{T_2 - T_1} dt \label{eq:fullweight3}
\end{equation}

By multiplying equation (\ref{eq:fullweight1}) by $V_{0}
\int_{0}^{T} w_{3} {(\int_{T_1}^{T_2}C_{a}(u)du)}/{(T_2 - T_1)} dt$
and equation (\ref{eq:fullweight3}) by $V_{0} \int_{0}^{T} w_{1}
{(\int_{T_1}^{T_2}C_{a}(u)du)}/{(T_2 - T_1)} dt$, and then
subtracting the two, we may eliminate the $V_{0}$ term.  A similar
operation can be performed on equation (\ref{eq:fullweight2}) and
equation (\ref{eq:fullweight3}).  This leaves two equations that do
not contain $V_{0}$.  They may then be divided to produce:

%
\begin{equation}
\hspace*{-1.0cm}
\frac{
\begin{array}{lcr}
\multicolumn{2}{l}{
\int_{0}^{T}\!\!w_{3}(t) \frac{(\int_{T_1}^{T_2}C_{a}(u)du)}{(T_2 - T_1)} dt \cdot 
\int_{0}^{T}\!\!w_{1}(t)A^{*}(t)dt\,\,-}&\\
&\multicolumn{2}{r} {\int_{0}^{T}\!\!w_{1}(t)
\frac{(\int_{T_1}^{T_2}C_{a}(u)du)}{(T_2 - T_1)} dt \cdot
\int_{0}^{T}\!\!w_{3}(t)A^{*}(t)dt}\end{array}
}
{
\begin{array}{lcr}
\multicolumn{2}{l}
{\int_{0}^{T}\!\!w_{3}(t) \frac{(\int_{T_1}^{T_2}C_{a}(u)du)}{(T_2 - T_1)} dt \cdot 
\int_{0}^{T}\!\!w_{2}(t)A^{*}(t)dt\,\,-}&\\
&\multicolumn{2}{r}
{\int_{0}^{T}\!\!w_{2}(t) \frac{(\int_{T_1}^{T_2}C_{a}(u)du)}{(T_2 - T_1)} dt \cdot 
\int_{0}^{T}\!\!w_{3}(t)A^{*}(t)dt}\end{array}
}
 =
\frac{
K_{1} \left\{\!\!\!\! \begin{array}{c}
\begin{array}{lcr}\multicolumn{2}{l}
{\int_{0}^{T}\!\!w_{3}(t) \frac{(\int_{T_1}^{T_2}C_{a}(u)du)}{(T_2 -
T_1)} dt \cdot
\int_{0}^{T}\!\!w_{1}(t) \frac{(\int_{T_1}^{T_2}C_{a}(u) \otimes
e^{-k_{2}u} du)}{(T_2 - T_1)}\, dt\,\,-}&
\\ 
&\multicolumn{2}{r} {\int_{0}^{T}\!\!w_{1}(t)
\frac{(\int_{T_1}^{T_2}C_{a}(u)du)}{(T_2 - T_1)} dt \cdot
\int_{0}^{T}\!\!w_{3}(t)  \frac{(\int_{T_1}^{T_2}C_{a}(u) \otimes
e^{-k_{2}u} du)}{(T_2 - T_1)}\, dt}
\end{array} \end{array} \!\!\!\! \right\} }
{
K_{1} \left\{ \!\!\!\! \begin{array}{c}
\begin{array}{lcr} 
\multicolumn{2}{l}{\int_{0}^{T}\!\!w_{3}(t) \frac{(\int_{T_1}^{T_2}C_{a}(u)du)}{(T_2 - T_1)} dt \cdot 
\int_{0}^{T}\!\!w_{2}(t) \frac{(\int_{T_1}^{T_2}C_{a}(u) \otimes
e^{-k_{2}u} du)}{(T_2 - T_1)}\, dt\,\,-} &
\\
&\multicolumn{2}{r}{\int_{0}^{T}\!\!w_{2}(t)
\frac{(\int_{T_1}^{T_2}C_{a}(u)du)}{(T_2 - T_1)} dt \cdot
\int_{0}^{T}\!\!w_{3}(t)  \frac{(\int_{T_1}^{T_2}C_{a}(u) \otimes
e^{-k_{2}u} du)}{(T_2 - T_1)}\, dt} \end{array} \end{array} \!\!\!\!
\right\} }
\label{eq:k1two}
\end{equation}

The $K_{1}$ term cancels out of both the numerator and denominator of
equation (\ref{eq:k1two}), leaving an equation that only involves
$k_{2}$.  As with the equation in section \ref{sec:double_weight},
this is very difficult to solve for $k_{2}$.  Therefore, a look-up
table was again used.  Once the table matching values of $k_{2}$ with
values of the right hand side of equation (\ref{eq:k1two}) has been
created, we may evaluate $k_{2}$ through simple lookup.  With the
$k_{2}$ data computed, finding $K_{1}$ is simply a matter of
evaluating either the numerator or denominator of equation
(\ref{eq:k1two}) without cancelling $K_{1}$.  With both $K_{1}$ and
$k_{2}$ known, we may find $V_{0}$ by evaluating equation
(\ref{eq:2comp4}).

\subsection{Delay and Dispersion Correction}
\label{sec:blood_correction}

Since the blood samples used to estimate $C_a(t)$ are taken from the
subject's arm, the activity data gathered from them must be corrected
for delay and dispersion within the body.  In order to perform the
delay correction, we used the technique of Iida, by performing a
least squares fitting of the equation:

\begin{equation}
A^{*}(t) = \frac{\int_{T_1}^{T_2} \alpha \left[ C_a(t) \otimes e^{-\beta
t} \right] + \gamma C_a(t) dt}{T_2 - T_1} \label{eq:delay_correc}
\end{equation}

where $A^{*}(t)$ in this case is the average activity over grey
matter, $\int_{T_1}^{T_2}dt$ represents integration over frames,
$\alpha$, $\beta$, and $\gamma$ are the fitting parameters, and
$C_a(t)$ is the blood data.  The delay itself enters this equation by
generating $C_a(t)$ from:

\begin{equation}
C_a(t) = \bar{g}(t+\delta)
\label{eq:blood_delay}
\end{equation}

The function $\bar{g}$ is the result of performing dispersion
correction on the blood sample data.  This is represented by the
equation:

\begin{equation}
\bar{g}(t) = g(t) + \tau \frac{dg}{dt}
\end{equation}

which is an implicit deconvolution of the equation:

\begin{equation}
g(t) = \bar{g}(t) \otimes \left[ \frac{1}{\tau} e^{\frac{-t}{\tau}}
\right]
\end{equation}


%--------------------------------------------------------------
\newpage
\section{MATLAB Implementation}

\subsection{Introduction}

The previous section described the mathematical model used to
represent cerebral blood flow.  Both the simplified two-compartment
model (neglecting $V_0$), and the full two-compartment model were
implemented numerically in MATLAB.

\subsection{Program Structure}

\begin{figure}
\centerline{
\psfig{figure=flow.ps,angle=90,height=3.0in}}
\vspace{.25in}
\centerline{Figure 1: General program flow for rCBF analysis}
\end{figure}

The diagram in figure 1 shows the general flow of performing rCBF
analysis using MATLAB.  First, the blood data is prepared for
analysis by performing delay and dispersion correction.  Next the
lookup tables used in the analysis are calculated.  Finally, the
actual images are generated through table lookup using the lookup
tables computed in the previous step.

\begin{figure}
\centerline{
\psfig{figure=structure.ps,angle=90,height=3.0in}}
\vspace{.25in}
\centerline{Figure 2: Structure of rcbf2}
\end{figure}

Of course, the actual program implementation is slightly more complex
than this.  Figure 2 shows the full structure of the \code{rcbf2}
MATLAB function, which performs a full two-compartment rCBF analysis.
All of the main functions that are called by \code{rcbf2} are shown.
The \code{resampleblood} function returns the blood data to
\code{rcbf2} in an evenly sampled time domain (sampled every $1/2$
second).  This blood data is then passed to \code{correctblood},
which performs dispersion correction, and then delay correction by
calling \code{fit\_b\_curve}.  Finally, useful lookup tables are
calculated by \code{findintconvo}.

\subsection{Annotated Program Listings}

This section contains listings of all of the matlab programs
comprising the rCBF package.  Each program is broken into functional
sections, which are then annotated.

\subsubsection{RCBF1}
\label{sec:rcbf1_listing}

\begin{enumerate}

\item Check the input arguments.  If the number of arguments is
  incorrect, then print out the help information for the function,
  followed by an explanatory error message.  Additionally, we want to
  ensure that the arguments themselves make sense.  Therefore, we
  check that \code{slice} is a scalar, by checking that its largest
  dimension has a size of one (i.e. it is a $1 \times 1$ matrix).  If
  it is not, then we print the help, followed by an error message
  explaining the problem.
\begin{verbatim}
if (nargin == 2)
    progress = 0;
elseif (nargin ~= 3)
    help rcbf1
    error('Incorrect number of arguments.');
end

if (length(slice)~=1)
    help rcbf1
    error('<Slice> must be a scalar.');
end
\end{verbatim}

\item Get the images and image information.  This includes all of the
  frames for the slice being analyzed, the frame start times, the
  frame lengths, the mid-frame times, and the blood data.  The frame
  time information is returned by simple enquiries with the data
  handle \code{img} returned by \code{openimage}.  The blood data is
  returned by \code{resampleblood}, which gives the blood data in an
  evenly sampled time domain (every half second).  The blood data is
  then cross-calibration corrected by multiplying by the factor
  \code{XCAL}.  The cross-calibration converts from ${\rm Bq} /
  {\rm g_{blood}}$ to ${\rm nCi} / {\rm mL_{blood}}$, taking into
  account the calibration between the well counter and the PET
  scanner.  In order to maintain consistent units throughout the
  analysis, this data must then be converted from ${\rm nCi / ml_{blood}}$
  {\em back} to ${\rm Bq} / {\rm g_{blood}}$.  The actual PET
  images are then retrieved, and the units are again converted to
  ${\rm Bq} / {\rm g_{tissue}}$.  Any negative values present in
  the images are set to zero.
\begin{verbatim}
img = openimage(filename);
FrameTimes = getimageinfo (img, 'FrameTimes');
FrameLengths = getimageinfo (img, 'FrameLengths');
MidFTimes = FrameTimes + (FrameLengths / 2);

[g_even, ts_even] = resampleblood (img, 'even');

% Apply the cross-calibration factor, and convert back to Bq/g_blood 
XCAL = 0.11;
g_even = g_even*XCAL*37/1.05;

Ca_even = g_even;                % no delay/dispersion correction

PET = getimages (img, slice, 1:length(FrameTimes));
PET = PET * 37 / 1.05;           % convert to decay / (g_tissue * sec)
PET = PET .* (PET > 0);          % set all negative values to zero
ImLen = size (PET, 1);           % num of rows = length of image
\end{verbatim}

\item Calculate some useful integrals that are used several times in
  the rest of the program.  \code{PET\_int1}, and \code{PET\_int2} are
  weighted integrals of the PET data across frames (integrated with
  respect to time).  In particular, \code{PET\_int1} is the numerator
  of the left-hand-side of equation \ref{eq:1comp}, and
  \code{PET\_int2} is the denominator.  To get clean images out of the
  analysis, we wish to set all points outside of the head to zero.
  Therefore, we create a simple mask, and apply it to the weighted
  integrals.  Note the use of \code{rescale} to perform an
  ``in-place'' multiplication on \code{PET\_int1}.  This has the same
  effect as the more conventional MATLAB \verb|PET_int1 = PET_int1 .*
  mask|, but without making a copy of \code{PET\_int1}.
\begin{verbatim}
PET_int1 = trapz (MidFTimes, PET')';
PET_int2 = trapz (MidFTimes, PET' .* (MidFTimes * ones(1,ImLen)))';

mask = PET_int1 > mean (PET_int1);
rescale (PET_int1, mask);
rescale (PET_int2, mask);
\end{verbatim}

\item Calculate the left hand side of equation (\ref{eq:1comp}).
\begin{verbatim}
rL = PET_int1 ./ PET_int2;
\end{verbatim}

\item Assign the $k_2$ values to be used in the lookup table, and then
generate some more useful weighted integrals.  \code{findintconvo}
computes the function
\begin{equation}
C_{a}(t) \otimes e^{-k_{2}t}
\end{equation}
at all points in the evenly-resampled time domain \code{ts\_even}.
Then, it integrates across each individual frame (which run from $T_1$
to $T_2$; $T_1$ and $T_2$ in the following formula are implicitly
functions of the frame).  Then, the weighted integrals across {\em all} frames
are computed:
\begin{equation}
\int_{0}^{T} \frac
  {\int_{T_1}^{T_2} \left[ C_{a}(u) \otimes e^{-k_{2}u} \right] du}
  {T_2 - T_1} 
  w_i dt
\label{eq:convint}
\end{equation}
Here, $w_i$ is the weighting function; for the double-weighted
analysis it is either $1$ or $t$ as in the right hand side of equation
(\ref{eq:1comp}).  

Then, since we wish to relate $k_2$ to the values of these integrals,
\code{findintconvo} computes equation \ref{eq:convint} at a wide range
of values of $k_2$ (supplied by the argument \code{k2\_lookup}) for
each weighting function $w_i$.  (For the double-weighted method, $w_1
= 1$ and $w_2 = t$.)  Note that the supplied value of
\code{k2\_lookup} implies an assumption that no voxel in the image
will have a $k_2$ value outside the range $0 \ldots 3\, 
{\rm min}^{-1}$.)  See section \ref{sec:findintconvo_listing} for
information on the internal details of \code{findintconvo}.

\begin{verbatim}
k2_lookup = (0:0.02:3) / 60;
[conv_int1, conv_int2] = findintconvo (Ca_even, ts_even, k2_lookup,...
                            MidFTimes, FrameLengths, 1, MidFTimes);
\end{verbatim}

\item Calculate the right side of equation (\ref{eq:1comp}).
\begin{verbatim}
rR = conv_int1 ./ conv_int2;
\end{verbatim}

\item Generate the $k_2$ image through table lookup.  This is where we
  make use of the lookup tables generated in \code{findintconvo} for
  great time savings: \code{findintconvo} only has to compute equation
  \ref{eq:convint} (a comparatively slow operation) a few hundred
  times, but for that effort we get 16,384 values of $k_2$ very
  quickly.
\begin{verbatim}
k2 = lookup(rR, k2_lookup, rL);
\end{verbatim}

\item Generate the $K_1$ image through table lookup and division.
  \code{k2\_conv\_ints} contains the values of equation \ref{eq:convint}
  at the actual values of $k_2$ for this image, rather than at the
  artificial set \code{k2\_lookup}.  This step is where we solve the
  numerator of equation \ref{eq:1comp} for $K_1$.
\begin{verbatim}
k2_conv_ints = lookup (k2_lookup, conv_int1, k2);
K1 = PET_int1 ./ k2_conv_ints;
\end{verbatim}

\item Clean up the $K_1$ image by setting any NaN's and infinities to
zero, and close the image data set.
\begin{verbatim}
nuke = find (isnan (K1) | isinf (K1));
K1 (nuke) = zeros (size (nuke));
closeimage (img);
\end{verbatim}

\item Finally, $K_1$ is converted from the internal units [${\rm
    g_{blood} / g_{tissue}}$] to the standard units for rCBF
  analysis [${\rm mL_{blood} / (100\, g_{tissue} \cdot min)}$].
\begin{verbatim}
rescale (K1, 100*60/1.05);
\end{verbatim}

\end{enumerate}


\subsubsection{RCBF2}
\label{sec:rcbf2_listing}

\code{RCBF2} is essentially an extension of \code{RCBF1} with the
addition of a third weighting function (needed to calculate $V_0$) and
correction for the delay and dispersion of blood.  Also, RCBF2 adds
allows the user to specify a list of slices (as a vector) rather than
requiring a scalar \code{slice}.  This means that we add a loop
through all desired slices, so some of the code is rearranged to avoid
redoing the same work several times in the loop.

\begin{enumerate}
\item The function declaration line.  The output arguments \code{K1},
  \code{k2}, and \code{V0} will all be whole images---that is,
  assuming $128 \times 128$ PET data, they will be column vectors with
  16,384 elements.  \code{delta} will contain the blood delay term
  $\delta$ for each specified slice.

  Of the input arguments, only \code{filename} (the name of the MINC
  volume to process) and \code{slices} (the list of slices to process)
  are required.  The other three are boolean variables (i.e., they
  should be scalars with a value of either 0 or 1) that default to
  ``true'' (1).  \code{progress} controls whether RCBF2 prints
  progress information; \code{correction} decides whether or not it
  performs correction of the blood data for delay and dispersion; and
  \code{batch} controls whether selection of the mask used for
  delay/dispersion correction should be interactive or automatic (the
  default).  The latter two should {\em not} be changed when RCBF2 is
  being used for real data analysis, and are merely provided to speed
  things up when debugging.
  \begin{verbatim}
function [K1,k2,V0,delta] = rcbf2_slice ...
         (filename, slices, progress, correction, batch)
  \end{verbatim}

\item Check the input arguments.  We want to make sure that we have at
  least two input arguments (the filename and the list of slices).
  Then, we assign default values to \code{progress}, \code{correction}
  and \code{batch} if they were not supplied by the user.
\begin{verbatim}
if (nargin < 2)
   help rcbf2
   error ('Not enough input arguments');
elseif (nargin < 3)
   progress = 1;
   correction = 1;
   batch = 1;   
elseif (nargin < 4)
   batch = 1;
   correction = 1;
elseif (nargin < 5)
   batch = 1;
elseif (nargin > 5)
   help rcbf2
   error('Incorrect number of arguments.');
end
\end{verbatim}

\item Initialize the matrices that will hold the $K_1$, $k_2$, and
  $V_0$ images, as well as the vector to hold the value of $\delta$
  (the blood delay from equation \ref{eq:blood_delay}) for each slice.
  \begin{verbatim}
total_slices = length(slices);
K1 = zeros(16384,total_slices);
k2 = zeros(16384,total_slices);
V0 = zeros(16384,total_slices);
delta = zeros(1,total_slices);
  \end{verbatim}

\item Open the volume and get some preliminary information on frame
  times and lengths.
  \begin{verbatim}
img = openimage(filename);
if (getimageinfo (img, 'time') == 0)
   error ('Study is non-dynamic');
end

FrameTimes = getimageinfo (img, 'FrameTimes');
FrameLengths = getimageinfo (img, 'FrameLengths');
MidFTimes = FrameTimes + (FrameLengths / 2);
  \end{verbatim}

\item Read the blood data, perform cross-calibration, and convert
  units.  (See explanation in section \ref{sec:rcbf1_listing}.)
  \begin{verbatim}
[g_even, ts_even] = resampleblood (img, 'even');
XCAL = 0.11;
rescale(g_even, (XCAL*37/1.05));
  \end{verbatim}

\item Create the weighting functions, $w_1$, $w_2$, and $w_3$ from
  equations \ref{eq:fullweight1}--\ref{eq:fullweight3}.  Also here we
  initialize the list of $k_2$ values from which the lookup table will
  be generated.

  \begin{verbatim}
w1 = ones(length(MidFTimes), 1);
w2 = MidFTimes;
w3 = sqrt (MidFTimes);

k2_lookup = (-10:0.05:10) / 60;
  \end{verbatim}


\item At this point, we start the processing that is specific to each
  slice: read the PET data, perform delay/dispersion correction,
  generate the lookup table, and solve equation \ref{eq:k1two}.  Thus,
  we loop through all user-specified slices:
  \begin{verbatim}
for current_slice = 1:total_slices
  \end{verbatim}

\item Read in the PET data for the current slice, and rescale it
  convert from ${\rm nCi/mL_{tissue}}$ to ${\rm Bq/g_{tissue}}$.
  \begin{verbatim}
PET = getimages (img, slices(current_slice), 1:length(FrameTimes), PET);
rescale (PET, (37/1.05));
  \end{verbatim}

\item Compute the weighted integrals of the PET data.
  \begin{verbatim}
PET_int1 = ntrapz (MidFTimes, PET, w1);
PET_int2 = ntrapz (MidFTimes, PET, w2);
PET_int3 = ntrapz (MidFTimes, PET, w3);
  \end{verbatim}

  This uses \code{ntrapz}, the CMEX version of \code{trapz}, which has
  the useful feature of allowing a weighting function to be supplied.
  Thus, the first line of code above is equivalent to (but faster and
  less memory-intensive than)
  \begin{verbatim}
weight = ones (16384,1) * w1';
PETweighted = PET .* weight;
PET_int1 = trapz (MidFTimes, PETweighted');
  \end{verbatim}

\item Generate a simple mask based on \code{PET\_int1} (which is
  simply the PET data averaged across all frames), and mask using
  \code{rescale}.  Also, \code{mask} is cleared for memory efficiency.
  \begin{verbatim}
mask = PET_int1 > mean(PET_int1);
rescale (PET_int1, mask);
rescale (PET_int2, mask);
rescale (PET_int3, mask);
clear mask;
  \end{verbatim}

  The next three steps perform delay/dispersion correction of the
  blood data (see section \ref{sec:blood_correction}).  

%  In the actual
%  program, this code is in an \code{if (correction)} statement, making
%  blood correction optional.  This detail has been omitted here.

\item First, create a mask that is used to select gray matter only;
  the mask is a variation on that used to mask the weighted PET
  integrals above.  That is, simply select all voxels whose values are
  greater than some constant times the mean of \code{PET\_int1}.  If
  non-interactive mode is on (i.e.  \code{batch} = 1, the default
  behaviour), then this constant is hard-coded to 1.8\footnote{This
    constant was empirically selected because it works fairly well
    with ${\rm H_{2}\,^{15}O}$ CBF data.}; otherwise, the function
  \code{getmask} is run.  This allows the user to select the threshold
  value while displaying the resulting, masked PET data.
  \begin{verbatim}
if (batch)
  mask = PET_int1 > (1.8*mean(PET_int1));
else
  mask = getmask (PET_int1);
end
  \end{verbatim}

\item Use the mask to get the mean of all gray-matter voxels.
  Thus, we reduce the dynamic PET data (16,384 voxels sampled at
  $n$ points in time) to a single time-activity curve (average of
  gray-matter activity at $n$ points in time).
  \begin{verbatim}
A = (mean (PET (find(mask),:)))';
clear mask;
  \end{verbatim}

\item The actual delay/dispersion correction is performed by
  \code{correctblood}.  See sections \ref{sec:blood_correction}, and
  \ref{sec:correctblood_listing} for information on (respectively) the
  theoretical basis and the implementation of delay/dispersion
  correction.
  \begin{verbatim}
[ts_even, Ca_even, delta(:,current_slice)] = correctblood ...
    (A, FrameTimes, FrameLengths, g_even, ts_even, progress);
  \end{verbatim}

\item Generate tables of the three weighted integrals of $Ca(t)
  \otimes e^{-k_{2}t}$.  (Actually, we generate tables of this
  expression integrated across each individual frame, then integrated
  across all frames; the procedure is identical to that used in RCBF1
  except for the addition of a third weighting function and the
  greatly expanded range of possible values for $k_2$.)
  \begin{verbatim}
[conv_int1,conv_int2,conv_int3] = findintconvo (Ca_even,ts_even,...
   k2_lookup, MidFTimes, FrameLengths, 1, w2, w3);
  \end{verbatim}

\item Generate some additional useful integrals.  These are used more
  than once in the subsequent code, and so are calculated in advance
  to speed up the computation.  \code{Ca\_mft} is the blood data
  averaged over each frame.  This is taken as the value of the blood
  data at the mid-frame time.  Note that we must detect when the blood
  data does not cover all the frames that the PET data does; this is
  made easy because \code{nframeint} does the work for us.  In
  particular, if the start time of any frame (some element of
  \code{FrameTimes}) is less than the start time of blood data
  [\code{ts\_even(1)}], then \code{nframeint} returns \code{NaN}
  (not-a-number) in the element of \code{Ca\_mft} corresponding to that
  frame.  Similiary, if the end time of any frame (some element of
  \code{FrameTimes+FrameLengths}) is greater than the end time of
  blood data [\code{ts\_even(length(ts\_even))}], then \code{NaN}
  is also returned.  The frames that fall outside of the blood data
  are then not used in generating the weighted integrals of the blood data.
\begin{verbatim}
Ca_mft = nframeint (ts_even, Ca_even, FrameTimes, FrameLengths);      
select = ~isnan(Ca_mft);

if (sum(select) ~= length(FrameTimes))
  disp('Warning: blood data does not span frames.');
end
  
Ca_int1 = ntrapz(MidFTimes(select), Ca_mft(select), w1(select));
Ca_int2 = ntrapz(MidFTimes(select), Ca_mft(select), w2(select));
Ca_int3 = ntrapz(MidFTimes(select), Ca_mft(select), w3(select));
\end{verbatim}

\item Generate the lookup table relating $k_2$ to values of the right
hand side of equation (\ref{eq:k1two}).  We also calculate the left
hand side of equation (\ref{eq:k1two}), which will be used in the
generation of a $k_2$ image.  Here, we see the value of precomputing
all the terms of \code{rL} and \code{rR}---not only is the code fairly
straightforward [as long as you understand the correspondance between
the variables \code{Ca\_int{\it i\/}}, \code{PET\_int{\it i\/}} and
\code{conv\_int{\it i\/}}, and the terms of equation (\ref{eq:k1two})],
but the computation of \code{rL} and \code{rR} is very fast.

Note that since \code{PET\_int{\it i\/}} is an image (i.e. it contains
a value for each voxel in the slice), and \code{Ca\_int{\it i\/}} is a
scalar, then \code{rL} will be an image.  However, 
\code{conv\_int{\it i\/}} is a lookup table keyed on
\code{k2\_lookup}; that is, there it contains one value for every
value of $k_2$ presumed possible.  Thus, \code{rR} will be also be a
lookup table keyed on \code{k2\_lookup}.
\begin{verbatim}
rL = ((Ca_int3 * PET_int1) - (Ca_int1 * PET_int3)) ./ ...
      ((Ca_int3 * PET_int2) - (Ca_int2 * PET_int3));

rR = ((Ca_int3 * conv_int1) - (Ca_int1 * conv_int3)) ./ ...
      ((Ca_int3 * conv_int2) - (Ca_int2 * conv_int3));
\end{verbatim}

\item Since \code{rL} and \code{rR} are the left- and right-hand-sides
  of equation (\ref{eq:k1two}), we can use their equality to find
  $k_2$ for every voxel.  That is, we know \code{rL} for every voxel,
  and we know \code{rR} for a certain set of values of $k_2$.  Thus,
  we can use \code{rR} to interpolate values of $k_2$.  First,
  however, we must invert the current relationship between
  \code{k2\_lookup} and \code{rR}; that is, we must make
  \code{k2\_lookup} a lookup table keyed on the values of \code{rR}.
  MATLAB's \code{sort} function makes this quite easy: we can sort
  \code{rR} and get a vector containing the ``sort order'' in one
  step.  Since we need \code{k2\_lookup} in its original order later
  on, we make a copy called \code{k2\_sorted} (even though it's now
  scrambled) that is ordered according to \code{rR}.
\begin{verbatim}
[rR,sort_order] = sort (rR);
k2_sorted = k2_lookup (sort_order);
\end{verbatim}

\item Generate the $k_2$ image, through a simple table lookup.
Values of $k_2$ are chosen by finding the value of $k_2$ where
\code{rL} and \code{rR} are equal.
\begin{verbatim}
k2 = lookup(rR, k2_sorted, rL);
\end{verbatim}

\item Generate the $K_1$ image by evaluating the numerator of
equation (\ref{eq:k1two}).  All of the time consuming calculations
have already been performed, and we can evaluate the $\int_{0}^{T} w
(\int_{T_1}^{T_2} Ca(u) \otimes e^{-k_{2}u} du)/(T_2 - T_1) dt$ terms
through table lookup.
\begin{verbatim}
K1_numer = ((Ca_int3*PET_int1) - (Ca_int1 * PET_int3));
K1_denom = (Ca_int3 * lookup(k2_lookup,conv_int1,k2)) - ...
           (Ca_int1 * lookup(k2_lookup,conv_int3,k2));
K1 = K1_numer ./ K1_denom;
\end{verbatim}

\item Generate the $V_0$ image by evaluating equation
(\ref{eq:fullweight1}) directly.  Once again, we may get values for
the complicated part of the equation through simple table lookup.
\begin{verbatim}
V0 = (PET_int1 - (K1 .* lookup(k2_lookup,conv_int1,k2))) / Ca_int1;
\end{verbatim}

\item Clean up the images by removing NaN's and infinities (setting
them to zero).
\begin{verbatim}
nuke = find (isnan (K1));
K1 (nuke) = zeros (size (nuke));
nuke = find (isinf (K1));
K1 (nuke) = zeros (size (nuke));

nuke = find (isnan (V0));
V0 (nuke) = zeros (size (nuke));
nuke = find (isinf (V0));
V0 (nuke) = zeros (size (nuke));
\end{verbatim}

\item Convert from the units used internally to the standard units for
  rCBF analysis.
  \begin{verbatim}
rescale (K1, 100*60/1.05);
rescale (k2, 60);
rescale (V0, 100/1.05);
  \end{verbatim}

\item Finally, close the image file so that everything gets cleaned
up nicely.
\begin{verbatim}
closeimage (img);
\end{verbatim}

\end{enumerate}


\subsubsection{CORRECTBLOOD}
\label{sec:correctblood_listing}

\begin{enumerate}

\item Check the input arguments.
\begin{verbatim}
if ((nargin < 5) | (nargin > 6))
   help correctblood
   error ('Incorrect number of input arguments.')
end

progress = 0;                   % defaults in case of no options vector -
do_delay = 1;                   % may be overridden below
   
if (nargin == 6)                % options vector

   if (length(options)>=1)      % options vector given; if it has an
      progress = options(1);    % element 1, that will be progress
   end

   if (length(options)>=2)      % delay correction toggle supplied
      do_delay = options(2);
   end

   if (length(options)>=3)      % value to use for delta supplied
      delta = options(3);
   else                         % no delta value given, so use 0
      delta = 0;                
   end

end

if (progress) 
   disp ('Showing progress');
end

if (~do_delay) 
   disp (['No delay-fitting will be performed; will use delta = ' ...
           int2str(delta)]);
end
\end{verbatim}

\item Do the initial setup.
\begin{verbatim}
MidFTimes = FrameTimes + FrameLengths/2;
first60 = find (FrameTimes < 60);       % all frames in first
numframes = length(FrameTimes);         %  minute only

tau = 4;                                % dispersion constant

if (progress >= 2)
   figure;
   plot (ts_even, g_even, 'y:');
   title ('Blood activity: dotted=g(t), solid=g(t) + tau*dg/dt');
   drawnow
   hold on
end
\end{verbatim}

\item Do the dispersion correction.
\begin{verbatim}
[smooth_g_even, deriv_g] = ...
     deriv (3, length(ts_even), g_even, (ts_even(2)-ts_even(1)));
smooth_g_even(length(smooth_g_even)) = [];
deriv_g(length(deriv_g)) = [];
ts_even(length(smooth_g_even)) = [];
 
g_even = smooth_g_even + tau*deriv_g;

if (progress >= 2)
   plot (ts_even, g_even, 'r');
   drawnow
end
\end{verbatim}

\item Get ready to do delay correction.
\begin{verbatim}
A = A (first60);                        % chop off stuff after 60 sec
MidFTimes = MidFTimes (first60);        % first minute again

if (progress >= 2)
   figure;
   plot (MidFTimes, A, 'or');
   hold on
   title ('Average activity across gray matter');
   old_fig = gcf;
   drawnow;
end

% Here are the initial values of alpha, beta, and gamma, in units of:
%  alpha = (mL blood) / ((g tissue) * sec)
%  beta = 1/sec
%  gamma = (mL blood) / (g tissue)
% Note that these differ numerically from Hiroto's suggested initial
% values of [0.6, alpha/0.8, 0.03] only because of the different
% units on alpha of (mL blood) / ((100 g tissue) * min).

init = [.0001 .000125 .03];
\end{verbatim}

\item Do the delay correction by performing several curve fittings.
\begin{verbatim}
if (do_delay)

   if (progress), fprintf ('Performing fits...\n'), end
   deltas = -5:1:10;
   rss = zeros (length(deltas), 1);     % residual sum-of-squares
   params = zeros (length(deltas), 3);  % 3 parameters per fit
   options = [0 0.1];

   for i = 1:length(deltas)
      delta = deltas (i);
      if (progress), fprintf ('delta = %.1f', delta), end

      % Get the shifted activity function, g(t - delta), by shifting g(t)
      % to the right (ie. subtract delta from its actual times, ts_even)
      % and resample at the "correct" times ts_even).  Then do the 
      % three-parameter fit to optimise the function wrt. alpha, beta,
      % and gamma.  Plot this fit.  (Could get messy, but what the hell)

      shifted_g_even = lookup ((ts_even-delta), g_even, ts_even);
      g_select = find (~isnan (shifted_g_even));

      % Be really careful with the fitting.  If the algorithm you
      % choose makes args(2) a negative value, there will be
      % infinities in the result of b_curve, which will cause
      % the entire thing to bomb.

      options(2) = 1;
      options(3) = 1;

      final = fmins ('fit_b_curve', init, options, [], ...
                shifted_g_even (g_select), ts_even (g_select), ...
                A, FrameTimes, FrameLengths);

      params (i,:) = final;
      rss(i) = fit_b_curve (final, ...
                 shifted_g_even(g_select), ts_even(g_select), ...
                 A, FrameTimes, FrameLengths);
      init = final;
      if (progress)
         fprintf ('; final = [%g %g %g]; residual = %g\n', final, rss (i));

         if (progress >= 2)
            plot (MidFTimes, ...
             b_curve(final, shifted_g_even(g_select), ts_even(g_select), ...
             A, FrameTimes, FrameLengths));
            drawnow;
         end      % if graphical progress
      end      % if any progress
   end      % for delta

   [err, where] = min (rss);            % find smallest residual
   delta = deltas (where);              % delta for best fit

end      % if do_delay
\end{verbatim}

\item Now that we have a value for \code{delta}, perform the actual
delay correction (shift the blood data).  We must also remove NaN's
from the new data.  These appear if \code{lookup} cannot perform a
lookup at a point (ie. there is no corresponding point in the table).
They will therefore occur at the end points, where \code{ts\_even}
does not span \code{(ts\_even-delta)}.
\begin{verbatim}
% At this point either we have performed the delay-correction fitting to 
% get delta, or the caller set options(2) to zero so that delay-correction
% was not explicitly done.  In this case, delta will have been set either
% to zero or to options(3).

Ca_even = lookup ((ts_even-delta), g_even, ts_even);

nuke = find(isnan(Ca_even));
Ca_even(nuke) = [];

% Let's assume that the NaN's occur at the beginning or end of the data
% (not in the middle), and that we can therefore modify ts_even without
% screwing up the even time spacing.

new_ts_even = ts_even;
new_ts_even(nuke) = [];
\end{verbatim}
\end{enumerate}


\subsubsection{FINDINTCONVO}
\label{sec:findintconvo_listing}
\begin{enumerate}
\item Check the input arguments.
\begin{verbatim}
if ((nargin < 6) | (nargin > 8))
    help findintconvo
    error ('Incorrect number of input arguments.');
end
\end{verbatim}

\item Do some initial setup.  We need to get the sizes of various
vectors, and initialize vectors that we will fill element by element
later.  Initializing vectors to all zero before filling them allows
better memory management by MATLAB.
\begin{verbatim}
NumEvenTimes = length(ts_even);
NumFrames = length(midftimes);
fstart = midftimes - (flengths / 2);

TableSize = length (k2_lookup);
integrand = zeros (NumFrames, 1);

if (nargin >= 6); int1 = zeros (1, TableSize); end;
if (nargin >= 7); int2 = zeros (1, TableSize); end;
if (nargin == 8); int3 = zeros (1, TableSize); end;

% if w1 is empty, assume that it should be all ones

if isempty (w1)
   w1 = ones (size(NumFrames));
end
\end{verbatim}

\item Calculate each element of the integrals, one at a time.
Unfortunately, there does not seem to be any way to vectorize this
operation, and it must therefore be performed within an inefficient
\code{for} loop.  Since this function can take considerable time to
execute, it prints a period for every iteration of the loop to keep
the user awake.

\begin{verbatim}
for i = 1:TableSize

   fprintf('.')

   exp_fun = exp(-k2_lookup(i) * ts_even);
   convo = nconv(Ca_even, exp_fun, ts_even(2) - ts_even(1));

   integrand = nframeint (ts_even, convo(1:length(ts_even)),...
                          fstart, flengths);

   % w1 given?

   if (nargin >= 6)
      int1 (i) = ntrapz(midftimes, (w1 .* integrand));
   end
   
   % w2 given?

   if (nargin >= 7)
      int2 (i) = ntrapz(midftimes, (w2 .* integrand));
   end

   % w3 given?
   
   if (nargin == 8)
       int3 (i) = ntrapz(midftimes, (w3 .* integrand));
   end
end
\end{verbatim}
\end{enumerate}


\subsubsection{B\_CURVE}
\begin{enumerate}

\item Check for the correct number of fitting parameters.  We don't
want to be very strict about checking input arguments here since this
function gets called many times during curve fitting.
\begin{verbatim}
if (length(args) ~= 3), error ('Wrong number of fit parameters'), end;
\end{verbatim}

\item Do a straight forward evaluation of the function.  
\begin{verbatim}
% N.B.: alpha = args(1)
%        beta = args(2)
%       gamma = args(3)

expthing = exp(-args(2)*ts_even); 	% ts_even for the convolution
c = nconv(shifted_g_even,expthing,ts_even(2)-ts_even(1));
c = c (1:length(ts_even));		% chop off points outside of the time
					% domain we're interested in

% Calculate the two main terms of the expression, alpha * (convoluted
% stuff) and gamma * (shifted activity), and sum them.

i1 = args(1)*c;				% alpha * (convolution)
i2 = args(3)*shifted_g_even;		% gamma * g(t - delta)

i = i1+i2;

integral = nframeint (ts_even, i, fstart, flengths);
\end{verbatim}

\item Clean up any NaN's that have cropped up by setting them to zero.
Also, truncate the function to whatever length \code{A} is.
\begin{verbatim}
nuke = find (isnan (integral));
integral (nuke) = zeros (size (nuke));

integral = integral (1:length(A));
\end{verbatim}
\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%    TEMPORARILY END THE DOCUMENT HERE    %%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

%--------------------------------------------------------------
\newpage
\section{Using the rCBF Package}

\subsection{Preparing Blood Data}

The EMMA function \code{resampleblood} that is used in rCBF to get
the blood data expects the data to either be included in the image
MINC file, or to be contained in a netCDF file with a \code{.bnc}
ending.

In order to assist the user by creating the \code{.bnc} file, there
is a utility called \code{bloodtonc}.  This program takes a
\code{.cnt} file, and converts it to a \code{.bnc} file that will be
read by the rCBF package.

To perform the conversion, use FTP to transfer the \code{.cnt} file
from the VAX to the SGI using ASCII mode.  Next, type:

\begin{verbatim}

     bloodtonc filename.cnt filename.bnc

\end{verbatim}

where \code{filename} is the name of the file (eg.
\code{arnaud\_20547}).  In order for \code{resampleblood} to find the
\code{.bnc} file, it must be in the same directory as the \code{.mnc}
file that contains the images.  Therefore, make sure that they are in
the same directory before performing the analysis using rCBF.


\subsection{Doing the Analysis}

Once the blood and image files are prepared, the analysis can be
performed.  Start MATLAB by typing \code{matlab} at the shell prompt.
Starting the analysis is very straight forward.  You may type
\code{help rcbf2} to get information on running the rCBF package.
Basically, \code{rcbf2} is a MATLAB function that returns a $K_1$,
$k_2$, and $V_0$ image, as well as the delay found during blood delay
correction.  It requires the name of the MINC file that contains the
images, and the number of the slice to analyze.  Therefore, if we
wished to analyze slice 12 of \code{arnaud\_20547}, we would call
\code{rcbf2} as:

\begin{verbatim}

     [K1, k2, V0, delay] = rcbf2('arnaud_20547', 12);

\end{verbatim}

In this case, the semi-colon at the end is {\em very} important since
\code{rcbf2} will return the entire images.  If the semi-colon is
omitted, the $K_1$, $k_2$, and $V_0$ values for every pixel will be
echoed to the screen, which takes a considerable amount of time.

Once the images have been generated, they may be manipulated using
any of the normal EMMA tools (viewed with \code{viewimage}, saved
with \code{putimages}, etc.).


%--------------------------------------------------------------
\newpage
\section{MATLAB Functions}

\input{rcbf-help}

\end{document}






